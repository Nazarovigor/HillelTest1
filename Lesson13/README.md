# URL Analyzer
URL Analyzer is a tool for analyzing URLs and extracting links from web pages. This tool allows you to obtain a list of valid and invalid links on a page.

## Installation
1. Install the dependencies by running: pip install -r requirements.txt.
2. Run the program by executing: python Test.py -url or -pdf, where <url> is the URL to analyze <pdf> path to pdf file
## Usage
URL Analyzer offers the following features:

- Extracting links from a web page.
- Filtering links and obtaining a list of valid links.
- Saving the valid and broken links to separate text files.

To use the URL Analyzer, follow these steps:

1. Install the necessary dependencies as mentioned in the Installation section.
2. Run the program and provide the URL you want to analyze using the -url argument.
3. The program will fetch the web page and extract the links.
4. It will then validate each link and categorize them as valid or broken.
5. The program will save the valid links to the "valid_links.txt" file and the broken links to the "broken_links.txt" file.

**Note**: Ensure that you have a stable internet connection for the program to fetch and validate the links successfully.

## Contribution
Contributions are welcome! If you want to contribute to the URL Analyzer project, please follow these steps:

1. Fork the repository.
2. Create a new branch for your feature or bug fix.
3. Make the necessary changes and commit them.
4. Push your changes to your forked repository.
5. Create a pull request, describing the changes you have made.

Please make sure to adhere to the coding standards and follow the existing project structure.

## License
Feel free to use, modify, and distribute this code as per the terms of the license.